"""
–û—Å–Ω–æ–≤–Ω–æ–π AI –¥–≤–∏–∂–æ–∫ –¥–ª—è –ö—É—Ä–∞—Ç–æ—Ä–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π –ø–µ—Ä—Å–æ–Ω.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –¥–∏–∞–ª–æ–≥–æ–≤–∞—è –≤–æ—Ä–æ–Ω–∫–∞ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–µ–¥–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
"""
from typing import List, Dict, Optional
from datetime import datetime
from loguru import logger

from shared.persona import PersonaManager, PERSONA_CHARACTERISTICS
from shared.persona.hook_templates import HOOK_TEMPLATES
from shared.ai_clients.yandexgpt_client import YandexGPTClient
from curator_bot.ai.prompts import get_curator_system_prompt, get_rag_instruction, get_onboarding_context, SIGNATURE_PHRASES
from curator_bot.ai.segment_styles import extract_segment_from_source, should_filter_swear
from curator_bot.database.models import User, ConversationMessage
from curator_bot.funnels.conversational_funnel import get_conversational_funnel, ConversationalFunnel


class CuratorChatEngine:
    """
    –î–≤–∏–∂–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∫—É—Ä–∞—Ç–æ—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI –∏ RAG.
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä—Å–æ–Ω –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è.
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –¥–∏–∞–ª–æ–≥–æ–≤–∞—è –≤–æ—Ä–æ–Ω–∫–∞ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–µ–¥–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
    """

    def __init__(self, ai_client):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞

        Args:
            ai_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AI (Gemini –∏–ª–∏ OpenAI)
        """
        self.ai_client = ai_client

        # –°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä—Å–æ–Ω –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Å—Ç–∏–ª—è
        self.persona_manager = PersonaManager()
        self.use_persona_system = True  # –í–ö–õ–Æ–ß–ï–ù–û - –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Å—Ç–∏–ª—è –ø–æ–¥ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞

        # –î–∏–∞–ª–æ–≥–æ–≤–∞—è –≤–æ—Ä–æ–Ω–∫–∞ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–µ–¥–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        self.conversational_funnel = get_conversational_funnel()
        self.use_conversational_mode = True  # –í–∫–ª—é—á–∏—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤—ã–π —Ä–µ–∂–∏–º

        logger.info("Curator chat engine initialized with PersonaManager and ConversationalFunnel")

    async def generate_response(
        self,
        user: User,
        user_message: str,
        conversation_history: List[ConversationMessage],
        knowledge_fragments: Optional[List[str]] = None,
        max_history: int = 10,
        use_persona: bool = True
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∫—É—Ä–∞—Ç–æ—Ä–∞

        Args:
            user: –û–±—ä–µ–∫—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            knowledge_fragments: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            max_history: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
            use_persona: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –ø–µ—Ä—Å–æ–Ω –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Å—Ç–∏–ª—è

        Returns:
            str: –û—Ç–≤–µ—Ç –∫—É—Ä–∞—Ç–æ—Ä–∞
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Ç—Ä–∞—Ñ–∏–∫–∞
            user_segment = extract_segment_from_source(
                getattr(user, "traffic_source", None)
            )

            # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Å —É—á—ë—Ç–æ–º —Å–µ–≥–º–µ–Ω—Ç–∞)
            system_prompt = get_curator_system_prompt(
                user_name=user.first_name or "–ü–∞—Ä—Ç–Ω–µ—Ä",
                qualification=user.qualification,
                lessons_completed=user.lessons_completed,
                current_goal=user.current_goal,
                segment=user_segment,
            )

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            temperature = 0.7

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤–æ–π –≤–æ—Ä–æ–Ω–∫–∏ (—Ç–µ–ø–µ—Ä—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –ë–î-backed)
            if self.use_conversational_mode:
                funnel_instructions = await self.conversational_funnel.get_ai_instructions(
                    user_id=user.telegram_id,
                    message=user_message
                )
                system_prompt = system_prompt + "\n\n" + funnel_instructions
                logger.info(f"Added conversational funnel instructions for user {user.telegram_id}")

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ (–µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω)
            onboarding_context = await self._get_onboarding_context(user.telegram_id)
            if onboarding_context:
                system_prompt = system_prompt + "\n\n" + onboarding_context
                logger.info(f"Added onboarding context for user {user.telegram_id}")

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–Ω–µ–≤–Ω–∏–∫–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)
            if user.telegram_id in settings.admin_ids_list:
                diary_context = await self._get_diary_context()
                if diary_context:
                    system_prompt = system_prompt + "\n\n" + diary_context
                    logger.info(f"Added diary context for admin {user.telegram_id}")

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä—Å–æ–Ω—ã –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞
            if use_persona and self.use_persona_system:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–µ—Ä—Å–æ–Ω—É
                persona_context = self._get_adaptive_persona(user_message)

                if persona_context:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä—Å–æ–Ω–µ –≤ –ø—Ä–æ–º–ø—Ç
                    persona_enhancement = self.persona_manager.get_prompt_enhancement(persona_context)
                    system_prompt = system_prompt + "\n\n" + persona_enhancement

                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã hooks –¥–ª—è —ç—Ç–æ–π –ø–µ—Ä—Å–æ–Ω—ã
                    hook_examples = self._get_hook_examples(persona_context.persona_name)
                    if hook_examples:
                        system_prompt = system_prompt + "\n\n" + hook_examples

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ø–µ—Ä—Å–æ–Ω—ã
                    temperature = persona_context.temperature

                    logger.info(
                        f"Using persona {persona_context.persona_name} for user {user.telegram_id}"
                    )

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
            context = self._prepare_context(conversation_history, max_history)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            if knowledge_fragments:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º RAG –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                logger.info(f"Generating RAG response for user {user.telegram_id}")
                response = await self.ai_client.generate_with_rag(
                    system_prompt=system_prompt,
                    user_message=user_message,
                    knowledge_fragments=knowledge_fragments,
                    context=context,
                    temperature=temperature
                )
            else:
                # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                logger.info(f"Generating standard response for user {user.telegram_id}")
                response = await self.ai_client.generate_response(
                    system_prompt=system_prompt,
                    user_message=user_message,
                    context=context,
                    temperature=temperature
                )

            # POST-PROCESSING: —É–±–∏—Ä–∞–µ–º markdown, —ç–º–æ–¥–∑–∏, AI-—Å–ª–æ–≤–∞, –æ–±—Ä–µ–∑–∞–µ–º
            response = self._clean_curator_response(response)

            # –§–∏–ª—å—Ç—Ä –º–∞—Ç–∞ –¥–ª—è mama-—Å–µ–≥–º–µ–Ω—Ç–∞
            if user_segment and should_filter_swear(user_segment):
                response = self._filter_swear_words(response)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)
            self._validate_response(response)

            logger.info(f"Response generated successfully for user {user.telegram_id}")
            return response

        except Exception as e:
            logger.error(f"Error generating response with primary AI: {e}")

            # Runtime fallback –Ω–∞ YandexGPT
            try:
                logger.warning("Trying YandexGPT as fallback...")
                fallback_client = YandexGPTClient()

                if knowledge_fragments:
                    response = await fallback_client.generate_with_rag(
                        system_prompt=system_prompt,
                        user_message=user_message,
                        knowledge_fragments=knowledge_fragments,
                        context=context,
                        temperature=temperature
                    )
                else:
                    response = await fallback_client.generate_response(
                        system_prompt=system_prompt,
                        user_message=user_message,
                        context=context,
                        temperature=temperature
                    )

                response = self._clean_curator_response(response)
                self._validate_response(response)
                logger.info(f"YandexGPT fallback successful for user {user.telegram_id}")
                return response

            except Exception as fallback_error:
                logger.error(f"YandexGPT fallback also failed: {fallback_error}")
                return self._get_fallback_response()

    def _clean_curator_response(self, response: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –∫—É—Ä–∞—Ç–æ—Ä–∞ –æ—Ç markdown, —ç–º–æ–¥–∑–∏ –∏ –ª–∏—à–Ω–µ–≥–æ.

        V3: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —á–∏—Å—Ç–∫–∞ ‚Äî –Ω–æ–ª—å —ç–º–æ–¥–∑–∏, –∑–∞–º–µ–Ω–∞ AI-—Å–ª–æ–≤, –æ–±—Ä–µ–∑–∫–∞ –¥–ª–∏–Ω—ã.
        """
        import re
        from curator_bot.ai.curator_style import replace_ai_words

        # 1. –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ markdown (# ## ### ####)
        response = re.sub(r'^#{1,4}\s+(.+)$', r'\1', response, flags=re.MULTILINE)

        # 2. –£–±–∏—Ä–∞–µ–º **–∂–∏—Ä–Ω—ã–π** ‚Üí –∂–∏—Ä–Ω—ã–π
        response = re.sub(r'\*\*([^*]+)\*\*', r'\1', response)

        # 3. –£–±–∏—Ä–∞–µ–º *–∫—É—Ä—Å–∏–≤* ‚Üí –∫—É—Ä—Å–∏–≤
        response = re.sub(r'\*([^*]+)\*', r'\1', response)

        # 4. –£–±–∏—Ä–∞–µ–º –í–°–ï —ç–º–æ–¥–∑–∏ (–∂–µ–ª–µ–∑–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ ‚Äî –Ω–æ–ª—å)
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # —Å–º–∞–π–ª—ã
            "\U0001F300-\U0001F5FF"  # —Å–∏–º–≤–æ–ª—ã –∏ –ø–∏–∫—Ç–æ–≥—Ä–∞–º–º—ã
            "\U0001F680-\U0001F6FF"  # —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç
            "\U0001F1E0-\U0001F1FF"  # —Ñ–ª–∞–≥–∏
            "\U00002702-\U000027B0"  # —Ä–∞–∑–Ω–æ–µ
            "\U000024C2-\U0001F251"  # enclosed
            "\U0001F900-\U0001F9FF"  # supplemental
            "\U0001FA00-\U0001FA6F"  # chess
            "\U0001FA70-\U0001FAFF"  # symbols extended
            "\U00002600-\U000026FF"  # misc symbols
            "\U0000FE00-\U0000FE0F"  # variation selectors
            "\U0000200D"             # zero width joiner
            "\U00000023\U0000FE0F\U000020E3"  # keycap
            "\U0000002A\U0000FE0F\U000020E3"
            "\U00000030-\U00000039\U0000FE0F\U000020E3"
            "]+",
            flags=re.UNICODE
        )
        response = emoji_pattern.sub('', response)

        # 5. –£–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–∫–∏ —Å —Ç–∏—Ä–µ/–±—É–ª–ª–µ—Ç–∞–º–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        response = re.sub(r'^[-‚Ä¢]\s+', '', response, flags=re.MULTILINE)

        # 6. –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (1. 2. 3.)
        response = re.sub(r'^\d+\.\s+', '', response, flags=re.MULTILINE)

        # 7. –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–±–æ–ª—å—à–µ 2 –ø–æ–¥—Ä—è–¥)
        response = re.sub(r'\n{3,}', '\n\n', response)

        # 8. –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∏–ø–∞ "–ß—Ç–æ –≤–∞–∂–Ω–æ:", "–ö–∞–∫ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å:"
        response = re.sub(r'^[–ê-–Ø–∞-—èA-Za-z\s]+:\s*$', '', response, flags=re.MULTILINE)

        # 9. –ó–∞–º–µ–Ω—è–µ–º AI-—Å–ª–æ–≤–∞ –Ω–∞ –∂–∏–≤—ã–µ –∞–Ω–∞–ª–æ–≥–∏
        response = replace_ai_words(response)

        # 10. –û–±—Ä–µ–∑–∫–∞ –¥–ª–∏–Ω—ã: –º–∞–∫—Å–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤
        response = response.strip()
        if len(response) > 500:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–æ—á–∫—É –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 500 —Å–∏–º–≤–æ–ª–æ–≤
            cut_pos = max(
                response.rfind('.', 0, 500),
                response.rfind('?', 0, 500),
                response.rfind('!', 0, 500),
            )
            if cut_pos > 100:  # –ù–∞—à–ª–∏ —Ä–∞–∑—É–º–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏
                response = response[:cut_pos + 1]
            else:
                response = response[:500]

        # 11. –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã (–ø–æ—Å–ª–µ –∑–∞–º–µ–Ω AI-—Å–ª–æ–≤)
        response = re.sub(r'  +', ' ', response)

        return response.strip()

    @staticmethod
    def _filter_swear_words(text: str) -> str:
        """–ó–∞–º–µ–Ω–∞ –º–∞—Ç–∞ –Ω–∞ –º—è–≥–∫–∏–µ –∞–Ω–∞–ª–æ–≥–∏ (–¥–ª—è mama-—Å–µ–≥–º–µ–Ω—Ç–∞)."""
        import re
        replacements = {
            "–±–ª—è—Ç—å": "–±–ª–∏–Ω", "–±–ª—è": "–±–ª–∏–Ω", "–±–ª*–Ω": "–±–ª–∏–Ω",
            "–ø–∏–∑–¥–µ—Ü": "—É–∂–∞—Å", "–ø–ø—Ü": "–∫–æ—à–º–∞—Ä", "–ø–∑–¥—Ü": "–∫–æ—à–º–∞—Ä",
            "–Ω–∞—Ö—É–π": "–Ω–∞—Ñ–∏–≥", "–Ω–∞—Ö—É—è": "–∑–∞—á–µ–º", "—Ö—É–π": "—Ñ–∏–≥",
            "—Ö—É–π–Ω—è": "–µ—Ä—É–Ω–¥–∞", "—Ö—É–π–Ω—é": "–µ—Ä—É–Ω–¥—É",
            "—Å—É–∫–∞": "–∂–µ—Å—Ç—å", "—ë–±–∞–Ω—ã–π": "–∂—É—Ç–∫–∏–π", "–µ–±–∞–Ω—ã–π": "–∂—É—Ç–∫–∏–π",
            "—ë–±": "–±–ª–∏–Ω", "–µ–±": "–±–ª–∏–Ω",
            "–ø–∏–∑–¥": "—Ñ–∏–≥", "–∑–∞–ª—É–ø": "—Ñ–∏–≥",
        }
        for swear, replacement in replacements.items():
            text = re.sub(re.escape(swear), replacement, text, flags=re.IGNORECASE)
        return text

    def _validate_response(self, response: str) -> None:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ‚Äî –ª–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç).
        –ê–Ω–∞–ª–æ–≥ validate_post() –∏–∑ content manager.
        """
        from content_manager_bot.ai.style_dna import check_anti_ai_words

        ai_words = check_anti_ai_words(response)
        if ai_words:
            logger.warning(f"AI words in curator response (post-cleanup): {ai_words}")

    def _get_hook_examples(self, persona_name: str) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã hooks –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–µ—Ä—Å–æ–Ω—ã.

        Args:
            persona_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω—ã (expert, friend, rebel –∏ —Ç.–¥.)

        Returns:
            str: –ü—Ä–∏–º–µ—Ä—ã hooks –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        """
        import random

        hooks = HOOK_TEMPLATES.get(persona_name, [])
        if not hooks:
            return ""

        # –ë–µ—Ä—ë–º 5-7 —Å–ª—É—á–∞–π–Ω—ã—Ö hooks –∫–∞–∫ –ø—Ä–∏–º–µ—Ä—ã
        sample_size = min(7, len(hooks))
        sampled_hooks = random.sample(hooks, sample_size)

        hook_examples = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üé£ –ü–†–ò–ú–ï–†–´ HOOKS –î–õ–Ø –¢–í–û–ï–ì–û –°–¢–ò–õ–Ø
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —Ñ—Ä–∞–∑—ã —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ—Ç–≤–µ—Ç —Ü–µ–ø–ª—è—é—â–µ:

"""
        for hook in sampled_hooks:
            template = hook["template"]
            # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã
            if "{topic}" in template:
                template = template.replace("{topic}", "–∫–æ–ª–ª–∞–≥–µ–Ω")
            if "{product}" in template:
                template = template.replace("{product}", "ED Smart")
            if "{myth}" in template:
                template = template.replace("{myth}", "'–≤—Å–µ –ë–ê–î—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ'")
            if "{percentage}" in template:
                template = template.replace("{percentage}", "80")

            hook_examples += f"‚Ä¢ {template}\n"

        hook_examples += "\n‚ö° –í–ê–ñ–ù–û: Hooks –∏—Å–ø–æ–ª—å–∑—É–π –ï–°–¢–ï–°–¢–í–ï–ù–ù–û, –∫–æ–≥–¥–∞ –æ–Ω–∏ —É–º–µ—Å—Ç–Ω—ã!"

        return hook_examples

    def _get_adaptive_persona(self, user_message: str):
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥:
        - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        - –¢–∏–ø –≤–æ–ø—Ä–æ—Å–∞
        - –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            PersonaContext –∏–ª–∏ None
        """
        message_lower = user_message.lower()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω/—É—Å—Ç–∞–ª -> tired –∏–ª–∏ friend
        sad_keywords = ["—É—Å—Ç–∞–ª", "–Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è", "—Å–ª–æ–∂–Ω–æ", "—Ç—Ä—É–¥–Ω–æ", "–±—Ä–æ—Å–∏—Ç—å", "–Ω–µ –º–æ–≥—É", "—Ç—è–∂–µ–ª–æ", "–ø–ª–æ—Ö–æ"]
        if any(word in message_lower for word in sad_keywords):
            self.persona_manager.generate_mood(force_category="sadness", force_intensity="medium")
            return self.persona_manager.get_persona_context(post_type="personal")

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö -> expert
        product_keywords = ["–ø—Ä–æ–¥—É–∫—Ç", "—Å–æ—Å—Ç–∞–≤", "–∫–∞–∫ –ø—Ä–∏–Ω–∏–º–∞—Ç—å", "–¥–æ–∑–∏—Ä–æ–≤–∫–∞", "–≤–∏—Ç–∞–º–∏–Ω", "–∫–æ–ª–ª–∞–≥–µ–Ω", "energy diet"]
        if any(word in message_lower for word in product_keywords):
            self.persona_manager.generate_mood(force_category="interest", force_intensity="medium")
            return self.persona_manager.get_persona_context(post_type="product")

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–µ–ø—Ç–∏–∫ –∏–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—Ç—Å—è -> expert –∏–ª–∏ rebel
        skeptic_keywords = ["—Ä–∞–∑–≤–æ–¥", "–ø–∏—Ä–∞–º–∏–¥–∞", "–Ω–µ –≤–µ—Ä—é", "–∑–∞—á–µ–º", "—Å–º—ã—Å–ª", "–ø–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ", "–æ–±–º–∞–Ω"]
        if any(word in message_lower for word in skeptic_keywords):
            self.persona_manager.generate_mood(force_category="anger", force_intensity="light")
            return self.persona_manager.get_persona_context(post_type="myth_busting")

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–¥—É–µ—Ç—Å—è/–¥–µ–ª–∏—Ç—Å—è —É—Å–ø–µ—Ö–æ–º -> friend –∏–ª–∏ crazy
        happy_keywords = ["–ø–æ–ª—É—á–∏–ª–æ—Å—å", "—É—Ä–∞", "–∫—Ä—É—Ç–æ", "—Å—É–ø–µ—Ä", "—Å–ø–∞—Å–∏–±–æ", "–≤–∞—É", "–∫–ª–∞—Å—Å", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç"]
        if any(word in message_lower for word in happy_keywords):
            self.persona_manager.generate_mood(force_category="joy", force_intensity="strong")
            return self.persona_manager.get_persona_context(post_type="celebration")

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –±–∏–∑–Ω–µ—Å–µ -> expert –∏–ª–∏ friend
        business_keywords = ["–∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å", "–±–∏–∑–Ω–µ—Å", "–∫–æ–º–∞–Ω–¥–∞", "–ø–∞—Ä—Ç–Ω—ë—Ä", "–∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", "–±–æ–Ω—É—Å", "–¥–æ—Ö–æ–¥"]
        if any(word in message_lower for word in business_keywords):
            self.persona_manager.generate_mood(force_category="trust", force_intensity="medium")
            return self.persona_manager.get_persona_context(post_type="business")

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å—Ç–∏–ª—å
        self.persona_manager.generate_mood(force_category="trust", force_intensity="light")
        return self.persona_manager.get_persona_context(post_type="tips")

    def _prepare_context(
        self,
        messages: List[ConversationMessage],
        max_messages: int
    ) -> List[Dict[str, str]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            max_messages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            List[Dict]: –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "user", "content": "..."}]
        """
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
        recent_messages = sorted(messages, key=lambda x: x.timestamp)[-max_messages:]

        context = []
        for msg in recent_messages:
            context.append({
                "role": "user" if msg.sender == "user" else "assistant",
                "content": msg.message_text
            })

        return context

    def _get_fallback_response(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∞—Å–Ω–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return """–ë–ª—è, —É –º–µ–Ω—è —Ç—É—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã. –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –ø–∞—Ä—É –º–∏–Ω—É—Ç –∏–ª–∏ –Ω–∞–ø–∏—à–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é."""

    async def analyze_user_intent(self, user_message: str) -> Dict[str, any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–º–µ—Ä–µ–Ω–∏–∏ (type, category, urgency)
        """
        # –ü—Ä–æ—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        message_lower = user_message.lower()

        intent = {
            "type": "general",
            "category": "other",
            "urgency": "normal",
            "keywords": []
        }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–∞
        # PRODUCTS - –ø—Ä–æ–¥—É–∫—Ç—ã NL International
        product_keywords = [
            "–ø—Ä–æ–¥—É–∫—Ç", "energy diet", "–∫–æ–∫—Ç–µ–π–ª—å", "–∫—Ä–µ–º", "–≤–∏—Ç–∞–º–∏–Ω",
            "–∫–æ–ª–ª–∞–≥–µ–Ω", "collagen", "–±–∞–¥", "–∞–¥–∞–ø—Ç–æ–≥–µ–Ω", "slim", "–ø–æ—Ö—É–¥–µ–Ω",
            "–∫–æ—Å–º–µ—Ç–∏–∫", "—É—Ö–æ–¥ –∑–∞ –∫–æ–∂", "—Å—ã–≤–æ—Ä–æ—Ç–∫", "–º–∞—Å–∫", "—à–∞–º–ø—É–Ω",
            "–≥–µ–ª—å", "–ª–æ—Å—å–æ–Ω", "—Ç–æ–Ω–∏–∫", "–ø–∏–ª–∏–Ω–≥", "—Å–∫—Ä–∞–±", "–∫–∞–ø—Å—É–ª",
            "—Å–ø—Ä–µ–π", "–Ω–∞–ø–∏—Ç–æ–∫", "–±–∞—Ç–æ–Ω—á–∏–∫", "—á–∞–π", "–∫–æ—Ñ–µ",
            # 3D Slim –ø—Ä–æ–¥—É–∫—Ç—ã:
            "metaboost", "–º–µ—Ç–∞–±—É—Å—Ç", "–º–µ—Ç–∞–±—É—Å—Ç", "–∂–∏—Ä–æ—Å–∂–∏–≥–∞—Ç", "l-–∫–∞—Ä–Ω–∏—Ç–∏–Ω", "–∫–∞—Ä–Ω–∏—Ç–∏–Ω",
            "draineffect", "–¥—Ä–µ–π–Ω", "–¥—Ä–µ–π–Ω—ç—Ñ—Ñ–µ–∫—Ç", "–¥–µ—Ç–æ–∫—Å", "–¥—Ä–µ–Ω–∞–∂", "–æ—Ç–µ–∫–∏", "–ª–∏—à–Ω—è—è –≤–æ–¥–∞",
            "white tea", "–±–µ–ª—ã–π —á–∞–π", "–≤–∞–π—Ç —Ç–∏", "–∞–ø–ø–µ—Ç–∏—Ç", "—Ç—è–≥–∞ –∫ —Å–ª–∞–¥–∫–æ–º", "—Å–ª–∞–¥–∫–æ–µ",
            "–∞–Ω—Ç–∏—Ü–µ–ª–ª—é–ª–∏—Ç", "—Ü–µ–ª–ª—é–ª–∏—Ç", "–≥–µ–ª—å hot", "–≥–µ–ª—å cold", "—Ö–æ—Ç", "–∫–æ–ª–¥",
            "—Ä–∞—Å—Ç—è–∂–∫–∏", "—Å—Ç—Ä–∏–∏", "shaping", "—à–µ–π–ø–∏–Ω–≥", "–º–æ–¥–µ–ª–∏—Ä—É—é—â", "lifting", "–ª–∏—Ñ—Ç–∏–Ω–≥",
            "3d slim", "3–¥ —Å–ª–∏–º", "slimdo"
        ]
        if any(word in message_lower for word in product_keywords):
            intent["category"] = "products"
            intent["keywords"].append("products")

        # BUSINESS - –º–∞—Ä–∫–µ—Ç–∏–Ω–≥-–ø–ª–∞–Ω, –∑–∞—Ä–∞–±–æ—Ç–æ–∫, –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–æ
        elif any(word in message_lower for word in [
            "–∑–∞—Ä–∞–±–æ—Ç", "–¥–æ—Ö–æ", "—Ç–æ–≤–∞—Ä–æ–æ–±–æ—Ä", "–ø—Ä–æ—Ü–µ", "–±–æ–Ω—É", "–∫–≤–∞–ª–∏—Ñ–∏–∫",
            "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–ø–ª–∞–Ω –≤–æ–∑–Ω–∞–≥", "–∫–∞—Ä—å–µ—Ä", "–º–µ–Ω–µ–¥–∂–µ—Ä", "–¥–∏—Ä–µ–∫—Ç–æ—Ä",
            "—Ä–µ—Ñ–µ—Ä–∞–ª", "–ø—Ä–∏–≥–ª–∞—Å–∏", "—Å—Å—ã–ª–∫", "–ø—Ä–æ–º–æ–∫–æ–¥", "—Å–∫–∏–¥–∫", "—Ä–µ–≥–∏—Å—Ç—Ä"
        ]):
            intent["category"] = "business"
            intent["keywords"].append("marketing_plan")

        # SALES - –ø—Ä–æ–¥–∞–∂–∏ –∏ —Ä–∞–±–æ—Ç–∞ —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏
        elif any(word in message_lower for word in [
            "–∫–∞–∫ –ø—Ä–æ–¥–∞—Ç—å", "–∫–ª–∏–µ–Ω—Ç", "–≤–æ–∑—Ä–∞–∂–µ–Ω", "–ø—Ä–æ–¥–∞–∂", "—Å–µ—Ç–µ–≤–æ–π",
            "–ø–∏—Ä–∞–º–∏–¥", "—Ä–∞–∑–≤–æ–¥", "–¥–æ—Ä–æ–≥–æ", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–æ—Ç–∫–∞–∑"
        ]):
            intent["category"] = "sales"
            intent["keywords"].append("sales_scripts")

        # TRAINING - –æ–±—É—á–µ–Ω–∏–µ, —Å–æ–≤–µ—Ç—ã, —Å–æ—Ü—Å–µ—Ç–∏
        elif any(word in message_lower for word in [
            "–æ–±—É—á–µ–Ω", "—É—Ä–æ–∫", "–∫—É—Ä—Å", "–º–∞—Å—Ç–µ—Ä", "—Å–æ–≤–µ—Ç", "–Ω–æ–≤–∏—á–æ–∫",
            "–Ω–∞—á–∞—Ç—å", "–ø–µ—Ä–≤—ã —à–∞–≥", "—Å–æ—Ü—Å–µ—Ç", "–∏–Ω—Å—Ç–∞–≥—Ä–∞–º", "telegram",
            "–∫–æ–Ω—Ç–µ–Ω—Ç", "–ø–æ—Å—Ç", "—Å—Ç–æ—Ä–∏—Å", "reels", "–≤–∏–¥–µ–æ"
        ]):
            intent["category"] = "training"
            intent["keywords"].append("training")

        # FAQ - –∑–∞–∫–∞–∑—ã, –¥–æ—Å—Ç–∞–≤–∫–∞, –æ–ø–ª–∞—Ç–∞
        elif any(word in message_lower for word in [
            "–∑–∞–∫–∞–∑", "–æ—Ñ–æ—Ä–º–∏", "–¥–æ—Å—Ç–∞–≤–∫", "–æ–ø–ª–∞—Ç", "–ø–æ–ª—É—á–∏", "–ø–æ—Å—ã–ª–∫",
            "—Ç—Ä–µ–∫", "–∞–¥—Ä–µ—Å", "–ø—É–Ω–∫—Ç –≤—ã–¥–∞—á", "–ø–æ—á—Ç", "–∫—É—Ä—å–µ—Ä", "—Å—Ç–æ–∏–º–æ—Å—Ç—å"
        ]):
            intent["category"] = "faq"
            intent["keywords"].append("faq")

        # COMPANY - –æ –∫–æ–º–ø–∞–Ω–∏–∏ NL International
        elif any(word in message_lower for word in [
            "–æ –∫–æ–º–ø–∞–Ω–∏–∏", "nl international", "–∏—Å—Ç–æ—Ä–∏—è", "–æ—Å–Ω–æ–≤–∞—Ç–µ–ª",
            "–∫–æ–≥–¥–∞ —Å–æ–∑–¥–∞–Ω", "—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç", "–≥–æ–ª–æ–≤–Ω–æ–π –æ—Ñ–∏—Å", "—Å—Ç—Ä–∞–Ω—ã"
        ]):
            intent["category"] = "company"
            intent["keywords"].append("company")

        # TEAM_BUILDING - –∫–æ–º–∞–Ω–¥–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
        elif any(word in message_lower for word in [
            "–∫–æ–º–∞–Ω–¥", "–ø–∞—Ä—Ç–Ω–µ—Ä", "—Å—Ç—Ä—É–∫—Ç—É—Ä", "–ª–∏–¥–µ—Ä", "–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫", "—Å–ø–æ–Ω—Å–æ—Ä"
        ]):
            intent["category"] = "team_building"
            intent["keywords"].append("team_building")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ä–æ—á–Ω–æ—Å—Ç—å
        if any(word in message_lower for word in ["—Å—Ä–æ—á–Ω–æ", "–±—ã—Å—Ç—Ä–æ", "–≤–∞–∂–Ω–æ", "–ø–æ–º–æ–≥–∏", "–ø—Ä–æ–±–ª–µ–º"]):
            intent["urgency"] = "high"

        logger.debug(f"Intent analysis: {intent}")
        return intent

    def should_use_rag(self, intent: Dict[str, any]) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞

        Args:
            intent: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è

        Returns:
            bool: True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RAG –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å NL International
        rag_categories = [
            "products",      # –ü—Ä–æ–¥—É–∫—Ç—ã
            "business",      # –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥-–ø–ª–∞–Ω, –∑–∞—Ä–∞–±–æ—Ç–æ–∫
            "sales",         # –ü—Ä–æ–¥–∞–∂–∏, –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
            "training",      # –û–±—É—á–µ–Ω–∏–µ, —Å–æ—Ü—Å–µ—Ç–∏
            "faq",           # –ó–∞–∫–∞–∑—ã, –¥–æ—Å—Ç–∞–≤–∫–∞
            "company",       # –û –∫–æ–º–ø–∞–Ω–∏–∏
            "team_building"  # –ö–æ–º–∞–Ω–¥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ training)
        ]
        return intent["category"] in rag_categories

    async def _get_diary_context(self, limit: int = 3) -> Optional[str]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –¥–Ω–µ–≤–Ω–∏–∫–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫—É—Ä–∞—Ç–æ—Ä–∞.
        –ö—É—Ä–∞—Ç–æ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ö —á—Ç–æ–±—ã ¬´–ø–æ–º–Ω–∏—Ç—å¬ª –æ —Å–æ–±—ã—Ç–∏—è—Ö –∏–∑ –∂–∏–∑–Ω–∏.
        """
        try:
            from sqlalchemy import select
            from shared.database.base import AsyncSessionLocal
            from content_manager_bot.database.models import DiaryEntry

            async with AsyncSessionLocal() as session:
                result = await session.execute(
                    select(DiaryEntry.entry_text, DiaryEntry.created_at)
                    .order_by(DiaryEntry.created_at.desc())
                    .limit(limit)
                )
                rows = result.all()

                if not rows:
                    return None

                block = (
                    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
                    "üìì –î–ù–ï–í–ù–ò–ö –î–ê–ù–ò–õ–ê (–Ω–µ–¥–∞–≤–Ω–∏–µ –∑–∞–ø–∏—Å–∏)\n"
                    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
                    "–ò—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Äî —Ç—ã ¬´–∑–Ω–∞–µ—à—å¬ª —ç—Ç–æ. –ù–ï —Ü–∏—Ç–∏—Ä—É–π –¥–æ—Å–ª–æ–≤–Ω–æ.\n\n"
                )
                for entry_text, created_at in rows:
                    date_str = created_at.strftime("%d.%m")
                    preview = entry_text[:300].replace("\n", " ").strip()
                    if len(entry_text) > 300:
                        preview += "..."
                    block += f"[{date_str}] {preview}\n\n"

                logger.info(f"[DIARY] Loaded {len(rows)} diary entries for curator context")
                return block

        except Exception as e:
            logger.warning(f"[DIARY] Failed to load diary context: {e}")
            return None

    async def _get_onboarding_context(self, telegram_id: int) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ë–î.

        Args:
            telegram_id: Telegram ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            str: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ –∏–ª–∏ None –µ—Å–ª–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω
        """
        try:
            from sqlalchemy import select
            from shared.database.base import AsyncSessionLocal
            from curator_bot.database.models import User, UserOnboardingProgress

            async with AsyncSessionLocal() as session:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                result = await session.execute(
                    select(User).where(User.telegram_id == telegram_id)
                )
                user = result.scalar_one_or_none()

                if not user:
                    return None

                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
                progress_result = await session.execute(
                    select(UserOnboardingProgress).where(
                        UserOnboardingProgress.user_id == user.id
                    )
                )
                progress = progress_result.scalar_one_or_none()

                if not progress:
                    return None

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                return get_onboarding_context(
                    current_day=progress.current_day,
                    completed_tasks=list(progress.completed_tasks or []),
                    is_completed=progress.is_completed
                )

        except Exception as e:
            logger.error(f"Error getting onboarding context: {e}")
            return None
