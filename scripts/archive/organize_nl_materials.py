"""
–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ NL –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ –ø–∞–ø–∫–∞–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤

–°–æ–∑–¥–∞—ë—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
/content/nl_knowledge/
‚îú‚îÄ‚îÄ energy_diet/
‚îÇ   ‚îú‚îÄ‚îÄ photos/
‚îÇ   ‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îî‚îÄ‚îÄ info.json (YouTube —Å—Å—ã–ª–∫–∏, –æ–ø–∏—Å–∞–Ω–∏–µ)
‚îú‚îÄ‚îÄ greenflash/
‚îú‚îÄ‚îÄ collagen/
‚îî‚îÄ‚îÄ ...

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/organize_nl_materials.py "–ø—É—Ç—å/–∫/—ç–∫—Å–ø–æ—Ä—Ç—É"
"""

import json
import re
import shutil
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import sys
import io

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')


class NLMaterialsOrganizer:
    def __init__(self, export_path: str):
        self.export_path = Path(export_path)
        self.messages = []

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º
        self.products_data = defaultdict(lambda: {
            'photos': [],
            'documents': [],
            'videos': [],
            'texts': [],
            'faq': [],
        })

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–æ–¥—É–∫—Ç–æ–≤ NL
        self.product_patterns = {
            # Energy Diet –ª–∏–Ω–µ–π–∫–∞
            'energy_diet': {
                'patterns': [
                    r'energy\s*diet', r'—ç–Ω–µ—Ä–¥–∂–∏\s*–¥–∞–π–µ—Ç', r'—ç–Ω–µ—Ä–¥–∂–∏\s*–¥–∏–µ—Ç',
                    r'\bed\b', r'–µ\.–¥\.', r'–µ–¥\s', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ'
                ],
                'name': 'Energy Diet',
                'category': 'functional_food'
            },
            'ed_smart': {
                'patterns': [r'ed\s*smart', r'smart', r'—Å–º–∞—Ä—Ç'],
                'name': 'ED Smart',
                'category': 'functional_food'
            },
            'ed_hd': {
                'patterns': [r'ed\s*hd', r'\bhd\b', r'—Ö–¥'],
                'name': 'ED HD',
                'category': 'functional_food'
            },

            # GreenFlash
            'greenflash': {
                'patterns': [
                    r'green\s*flash', r'greenflash', r'–≥—Ä–∏–Ω\s*—Ñ–ª–µ—à', r'–≥—Ä–∏–Ω—Ñ–ª–µ—à',
                    r'lymph\s*gyan', r'–ª–∏–º—Ñ\s*–≥—å—è–Ω',
                    r'lux\s*gyan', r'–ª—é–∫—Å\s*–≥—å—è–Ω',
                    r'uri\s*gyan', r'—É—Ä–∏\s*–≥—å—è–Ω',
                    r'livo\s*gyan', r'–ª–∏–≤–æ\s*–≥—å—è–Ω',
                    r'gut\s*vigyan', r'–≥–∞—Ç\s*–≤–∏–≥—å—è–Ω',
                    r'gyan', r'–≥—å—è–Ω', r'vigyan', r'–≤–∏–≥—å—è–Ω'
                ],
                'name': 'GreenFlash',
                'category': 'supplements'
            },

            # Collagen
            'collagen': {
                'patterns': [r'collagen', r'–∫–æ–ª–ª–∞–≥–µ–Ω'],
                'name': 'Collagen',
                'category': 'beauty'
            },

            # DrainEffect
            'draineffect': {
                'patterns': [r'drain\s*effect', r'draineffect', r'–¥—Ä–∞–π–Ω', r'–¥—Ä–µ–π–Ω', r'–¥–µ—Ç–æ–∫—Å'],
                'name': 'DrainEffect',
                'category': 'detox'
            },

            # 3D Slim
            '3d_slim': {
                'patterns': [r'3d\s*slim', r'3–¥\s*—Å–ª–∏–º', r'—Å–ª–∏–º', r'–ø–æ—Ö—É–¥–µ–Ω–∏–µ'],
                'name': '3D Slim',
                'category': 'weight_loss'
            },

            # Omega
            'omega': {
                'patterns': [r'omega', r'–æ–º–µ–≥–∞', r'dha', r'–¥–≥–∫', r'—Ä—ã–±–∏–π –∂–∏—Ä'],
                'name': 'Omega',
                'category': 'supplements'
            },

            # Vision Lecithin
            'vision_lecithin': {
                'patterns': [r'vision\s*lecithin', r'–ª–µ—Ü–∏—Ç–∏–Ω', r'lecithin', r'vision'],
                'name': 'Vision Lecithin',
                'category': 'supplements'
            },

            # ProHelper
            'prohelper': {
                'patterns': [r'prohelper', r'–ø—Ä–æ—Ö–µ–ª–ø–µ—Ä', r'pro\s*helper'],
                'name': 'ProHelper',
                'category': 'supplements'
            },

            # Imperial Herb
            'imperial_herb': {
                'patterns': [r'imperial\s*herb', r'–∏–º–ø–µ—Ä–∏–∞–ª\s*—Ö–µ—Ä–±', r'—Ç—Ä–∞–≤—è–Ω–æ–π —á–∞–π'],
                'name': 'Imperial Herb',
                'category': 'tea'
            },

            # Happy Smile (–∑—É–±–Ω–∞—è –ø–∞—Å—Ç–∞)
            'happy_smile': {
                'patterns': [r'happy\s*smile', r'—Ö—ç–ø–ø–∏\s*—Å–º–∞–π–ª', r'–∑—É–±–Ω–∞—è –ø–∞—Å—Ç–∞', r'–∑—É–±'],
                'name': 'Happy Smile',
                'category': 'cosmetics'
            },

            # –î–µ—Ç—Å–∫–∞—è –ª–∏–Ω–µ–π–∫–∞ NL'ka
            'nlka_baby': {
                'patterns': [r"nl'?ka\s*baby", r'–Ω–ª–∫–∞\s*–±–µ–π–±–∏', r'–¥–µ—Ç—Å–∫–æ–µ.*—Å –ø–µ—Ä–≤—ã—Ö –¥–Ω–µ–π', r'–¥–ª—è –Ω–æ–≤–æ—Ä–æ–∂–¥'],
                'name': "NL'ka Baby",
                'category': 'baby'
            },
            'nlka_kids': {
                'patterns': [r"nl'?ka\s*kids", r'–Ω–ª–∫–∞\s*–∫–∏–¥—Å', r'–¥–µ—Ç—Å–∫–æ–µ.*2-3', r'–¥–ª—è –¥–µ—Ç–µ–π'],
                'name': "NL'ka Kids",
                'category': 'baby'
            },
            'nlka_cosmetics': {
                'patterns': [r"nl'?ka.*–∫–æ—Å–º–µ—Ç–∏–∫–∞", r'–¥–µ—Ç—Å–∫–∞—è –∫–æ—Å–º–µ—Ç–∏–∫–∞', r'nlka_kosmetika'],
                'name': "NL'ka –ö–æ—Å–º–µ—Ç–∏–∫–∞",
                'category': 'baby'
            },

            # Occuba (–∫–æ—Å–º–µ—Ç–∏–∫–∞)
            'occuba': {
                'patterns': [r'occuba', r'–æ–∫–∫—É–±–∞', r'–∫–æ—Å–º–µ—Ç–∏–∫–∞ nl'],
                'name': 'Occuba',
                'category': 'cosmetics'
            },

            # Be Loved
            'beloved': {
                'patterns': [r'be\s*loved', r'–±–µ–ª–∞–≤–µ–¥', r'–±–∏\s*–ª–∞–≤–µ–¥'],
                'name': 'Be Loved',
                'category': 'cosmetics'
            },

            # –°–ø–æ—Ä—Ç
            'sport': {
                'patterns': [r'–ø—Ä–æ—Ç–µ–∏–Ω', r'protein', r'—Å–ø–æ—Ä—Ç', r'–≥–µ–π–Ω–µ—Ä', r'bcaa', r'pre-workout'],
                'name': '–°–ø–æ—Ä—Ç–∏–≤–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ',
                'category': 'sport'
            },

            # –ë–∏–∑–Ω–µ—Å/–°—Ç–∞—Ä—Ç–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã
            'starter_kits': {
                'patterns': [r'—Å—Ç–∞—Ä—Ç–æ–≤\w+\s*–Ω–∞–±–æ—Ä', r'starter', r'—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏', r'–±–∏–∑–Ω–µ—Å\s*–ø–∞–∫'],
                'name': '–°—Ç–∞—Ä—Ç–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã',
                'category': 'business'
            },

            # Calcium
            'calcium': {
                'patterns': [r'calcium', r'–∫–∞–ª—å—Ü–∏–π', r'ca\b'],
                'name': 'Calcium',
                'category': 'supplements'
            },
        }

        # –¢–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º —Ñ–∞–π–ª–æ–≤
        self.doc_types = {
            '.pdf': 'document',
            '.doc': 'document',
            '.docx': 'document',
            '.ppt': 'presentation',
            '.pptx': 'presentation',
            '.xls': 'spreadsheet',
            '.xlsx': 'spreadsheet',
            '.ogg': 'audio',
            '.mp3': 'audio',
            '.mp4': 'video',
        }

    def load_export(self) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç"""
        print("=" * 60)
        print("–ó–ê–ì–†–£–ó–ö–ê –≠–ö–°–ü–û–†–¢–ê")
        print("=" * 60)

        result_json = self.export_path / 'result.json'
        if not result_json.exists():
            print(f"[ERROR] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {result_json}")
            return False

        with open(result_json, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.messages = [m for m in data.get('messages', []) if m.get('type') == 'message']
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(self.messages)}")
        return True

    def get_text(self, msg: dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        text = msg.get('text', '')
        if isinstance(text, str):
            return text
        elif isinstance(text, list):
            parts = []
            for item in text:
                if isinstance(item, str):
                    parts.append(item)
                elif isinstance(item, dict):
                    parts.append(item.get('text', ''))
            return ' '.join(parts)
        return ''

    def detect_products(self, text: str, filename: str = '') -> list:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ–¥—É–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        search_text = (text + ' ' + filename).lower()
        found = []

        for product_id, info in self.product_patterns.items():
            for pattern in info['patterns']:
                if re.search(pattern, search_text, re.IGNORECASE):
                    found.append(product_id)
                    break

        return list(set(found)) if found else ['general']

    def extract_youtube_links(self, text: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç YouTube —Å—Å—ã–ª–∫–∏"""
        patterns = [
            r'https?://(?:www\.)?youtube\.com/watch\?v=([\w-]+)',
            r'https?://youtu\.be/([\w-]+)',
        ]
        links = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for video_id in matches:
                links.append(f'https://youtube.com/watch?v={video_id}')
        return links

    def extract_all_links(self, text: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏"""
        pattern = r'https?://[^\s<>\"\']+'
        return re.findall(pattern, text)

    def process_messages(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        print("\n" + "=" * 60)
        print("–ê–ù–ê–õ–ò–ó –°–û–û–ë–©–ï–ù–ò–ô")
        print("=" * 60)

        for idx, msg in enumerate(self.messages):
            if idx % 1000 == 0:
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{len(self.messages)}")

            text = self.get_text(msg)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–æ—Ç–æ
            if msg.get('photo'):
                photo_path = self.export_path / msg['photo']
                if photo_path.exists():
                    products = self.detect_products(text, msg['photo'])
                    for product in products:
                        self.products_data[product]['photos'].append({
                            'path': str(photo_path),
                            'filename': msg['photo'],
                            'context': text[:500],
                            'date': msg.get('date', ''),
                        })

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã/–¥–æ–∫—É–º–µ–Ω—Ç—ã
            if msg.get('file'):
                file_path = self.export_path / msg['file']
                filename = msg['file']
                products = self.detect_products(text, filename)

                ext = Path(filename).suffix.lower()
                doc_type = self.doc_types.get(ext, 'other')

                for product in products:
                    self.products_data[product]['documents'].append({
                        'path': str(file_path),
                        'filename': filename,
                        'type': doc_type,
                        'context': text[:300],
                        'date': msg.get('date', ''),
                    })

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∏–¥–µ–æ —Å—Å—ã–ª–∫–∏
            youtube_links = self.extract_youtube_links(text)
            if youtube_links:
                products = self.detect_products(text)
                for product in products:
                    for link in youtube_links:
                        self.products_data[product]['videos'].append({
                            'url': link,
                            'context': text[:300],
                            'date': msg.get('date', ''),
                        })

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞ (FAQ, –æ–ø–∏—Å–∞–Ω–∏—è)
            if text and len(text) > 200:
                products = self.detect_products(text)
                for product in products:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ –Ω–∞ FAQ
                    if any(kw in text.lower() for kw in ['–≤–æ–ø—Ä–æ—Å', '–æ—Ç–≤–µ—Ç', '?', '–∫–∞–∫', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º']):
                        self.products_data[product]['faq'].append({
                            'text': text,
                            'date': msg.get('date', ''),
                        })
                    else:
                        self.products_data[product]['texts'].append({
                            'text': text,
                            'date': msg.get('date', ''),
                        })

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "-" * 40)
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ü–†–û–î–£–ö–¢–ê–ú:")
        print("-" * 40)

        for product_id, data in sorted(self.products_data.items(), key=lambda x: -len(x[1]['photos'])):
            name = self.product_patterns.get(product_id, {}).get('name', product_id)
            print(f"\n{name}:")
            print(f"  –§–æ—Ç–æ: {len(data['photos'])}")
            print(f"  –î–æ–∫—É–º–µ–Ω—Ç—ã: {len(data['documents'])}")
            print(f"  –í–∏–¥–µ–æ: {len(data['videos'])}")
            print(f"  –¢–µ–∫—Å—Ç—ã: {len(data['texts'])}")
            print(f"  FAQ: {len(data['faq'])}")

    def organize_to_folders(self):
        """–û—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –≤—Å—ë –ø–æ –ø–∞–ø–∫–∞–º"""
        print("\n" + "=" * 60)
        print("–°–û–ó–î–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –ü–ê–ü–û–ö")
        print("=" * 60)

        output_base = Path(__file__).parent.parent / 'content' / 'nl_knowledge'
        output_base.mkdir(parents=True, exist_ok=True)

        stats = {'photos': 0, 'documents': 0}

        for product_id, data in self.products_data.items():
            if not any([data['photos'], data['documents'], data['videos']]):
                continue

            # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –ø—Ä–æ–¥—É–∫—Ç–∞
            product_dir = output_base / product_id
            product_dir.mkdir(exist_ok=True)

            # –ü–∞–ø–∫–∞ –¥–ª—è —Ñ–æ—Ç–æ
            if data['photos']:
                photos_dir = product_dir / 'photos'
                photos_dir.mkdir(exist_ok=True)

                # –ö–æ–ø–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ (–ø–µ—Ä–≤—ã–µ 100)
                seen = set()
                for idx, photo in enumerate(data['photos'][:100]):
                    src = Path(photo['path'])
                    if src.exists() and src.name not in seen:
                        seen.add(src.name)
                        dst = photos_dir / f"{idx:04d}_{src.name}"
                        try:
                            shutil.copy2(src, dst)
                            stats['photos'] += 1
                        except Exception as e:
                            pass

            # –ü–∞–ø–∫–∞ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if data['documents']:
                docs_dir = product_dir / 'documents'
                docs_dir.mkdir(exist_ok=True)

                seen = set()
                for doc in data['documents']:
                    src = Path(doc['path'])
                    if src.exists() and src.name not in seen:
                        seen.add(src.name)
                        dst = docs_dir / src.name
                        try:
                            shutil.copy2(src, dst)
                            stats['documents'] += 1
                        except Exception as e:
                            pass

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º info.json —Å –≤–∏–¥–µ–æ –∏ —Ç–µ–∫—Å—Ç–∞–º–∏
            info = {
                'product_id': product_id,
                'name': self.product_patterns.get(product_id, {}).get('name', product_id),
                'category': self.product_patterns.get(product_id, {}).get('category', 'other'),
                'videos': list({v['url'] for v in data['videos']}),  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∏–¥–µ–æ
                'photo_count': len(data['photos']),
                'document_count': len(data['documents']),
            }

            with open(product_dir / 'info.json', 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º FAQ –µ—Å–ª–∏ –µ—Å—Ç—å
            if data['faq']:
                faq_path = product_dir / 'faq.txt'
                with open(faq_path, 'w', encoding='utf-8') as f:
                    f.write(f"# FAQ –ø–æ {info['name']}\n\n")
                    seen_texts = set()
                    for item in data['faq']:
                        text_hash = item['text'][:100]
                        if text_hash not in seen_texts:
                            seen_texts.add(text_hash)
                            f.write(f"---\n{item['text']}\n\n")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø–∏—Å–∞–Ω–∏—è/—Ç–µ–∫—Å—Ç—ã
            if data['texts']:
                texts_path = product_dir / 'descriptions.txt'
                with open(texts_path, 'w', encoding='utf-8') as f:
                    f.write(f"# –û–ø–∏—Å–∞–Ω–∏—è {info['name']}\n\n")
                    seen_texts = set()
                    for item in data['texts'][:50]:  # –¢–æ–ø 50
                        text_hash = item['text'][:100]
                        if text_hash not in seen_texts:
                            seen_texts.add(text_hash)
                            f.write(f"---\n{item['text']}\n\n")

        print(f"\n–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ:")
        print(f"  –§–æ—Ç–æ: {stats['photos']}")
        print(f"  –î–æ–∫—É–º–µ–Ω—Ç—ã: {stats['documents']}")
        print(f"\n–ü–∞–ø–∫–∞: {output_base}")

        return output_base

    def create_summary_report(self, output_base: Path):
        """–°–æ–∑–¥–∞—ë—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á—ë—Ç"""
        print("\n" + "=" * 60)
        print("–°–û–ó–î–ê–ù–ò–ï –°–í–û–î–ù–û–ì–û –û–¢–ß–Å–¢–ê")
        print("=" * 60)

        report_path = output_base / 'SUMMARY.md'

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# –ú–∞—Ç–µ—Ä–∏–∞–ª—ã NL International\n\n")
            f.write(f"–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            f.write("## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º\n\n")

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            categories = defaultdict(list)
            for product_id, data in self.products_data.items():
                if any([data['photos'], data['documents'], data['videos']]):
                    cat = self.product_patterns.get(product_id, {}).get('category', 'other')
                    categories[cat].append((product_id, data))

            category_names = {
                'functional_food': 'üçΩÔ∏è –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ',
                'supplements': 'üíä –ë–ê–î—ã –∏ –¥–æ–±–∞–≤–∫–∏',
                'beauty': '‚ú® –ö—Ä–∞—Å–æ—Ç–∞',
                'cosmetics': 'üß¥ –ö–æ—Å–º–µ—Ç–∏–∫–∞',
                'baby': 'üë∂ –î–µ—Ç—Å–∫–∞—è –ª–∏–Ω–µ–π–∫–∞',
                'detox': 'üåø –î–µ—Ç–æ–∫—Å',
                'weight_loss': '‚öñÔ∏è –ü–æ—Ö—É–¥–µ–Ω–∏–µ',
                'tea': 'üçµ –ß–∞–∏',
                'sport': 'üí™ –°–ø–æ—Ä—Ç',
                'business': 'üíº –ë–∏–∑–Ω–µ—Å',
                'other': 'üì¶ –î—Ä—É–≥–æ–µ',
            }

            for cat, cat_name in category_names.items():
                if cat in categories:
                    f.write(f"\n### {cat_name}\n\n")
                    for product_id, data in categories[cat]:
                        name = self.product_patterns.get(product_id, {}).get('name', product_id)
                        f.write(f"#### {name}\n")
                        f.write(f"- –§–æ—Ç–æ: {len(data['photos'])}\n")
                        f.write(f"- –î–æ–∫—É–º–µ–Ω—Ç—ã: {len(data['documents'])}\n")
                        if data['videos']:
                            f.write(f"- –í–∏–¥–µ–æ: {len(data['videos'])}\n")
                            for v in list(set(v['url'] for v in data['videos']))[:5]:
                                f.write(f"  - {v}\n")
                        f.write("\n")

            # –í—Å–µ YouTube —Å—Å—ã–ª–∫–∏
            f.write("\n## –í—Å–µ –≤–∏–¥–µ–æ-—Å—Å—ã–ª–∫–∏\n\n")
            all_videos = set()
            for data in self.products_data.values():
                for v in data['videos']:
                    all_videos.add(v['url'])

            for url in sorted(all_videos):
                f.write(f"- {url}\n")

        print(f"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")

    def run(self):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
        if not self.load_export():
            return False

        self.process_messages()
        output_base = self.organize_to_folders()
        self.create_summary_report(output_base)

        print("\n" + "=" * 60)
        print("–ì–û–¢–û–í–û!")
        print("=" * 60)
        print(f"\n–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã –≤: {output_base}")
        print("\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞:")
        print("  /product_name/")
        print("    /photos/       - –§–æ—Ç–æ –ø—Ä–æ–¥—É–∫—Ç–∞")
        print("    /documents/    - PDF, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏")
        print("    info.json      - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ YouTube —Å—Å—ã–ª–∫–∏")
        print("    faq.txt        - –í–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã")
        print("    descriptions.txt - –û–ø–∏—Å–∞–Ω–∏—è")

        return True


def main():
    if len(sys.argv) > 1:
        export_path = sys.argv[1]
    else:
        export_path = input("–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º: ").strip('"')

    if not Path(export_path).exists():
        print(f"[ERROR] –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {export_path}")
        return

    organizer = NLMaterialsOrganizer(export_path)
    organizer.run()


if __name__ == "__main__":
    main()
