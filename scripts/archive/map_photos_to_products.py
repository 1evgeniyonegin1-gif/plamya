#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ —Ñ–æ—Ç–æ –∫ –ø—Ä–æ–¥—É–∫—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ Telegram —ç–∫—Å–ø–æ—Ä—Ç–∞ NL Assistant AI.

–ü–∞—Ç—Ç–µ—Ä–Ω –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ:
1. –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "üå±–≠–∫–æ–ø–µ–Ω–∫–∞ –¥–ª—è –º—ã—Ç—å—è —Ä—É–∫ HERBAL Hand foam")
2. –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è, —Å–æ—Å—Ç–∞–≤, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
3. –ö–Ω–æ–ø–∫–∞ "üì∑–§–æ—Ç–æ –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π"
4. –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –ø–æ–¥—Ä—è–¥

–°–∫—Ä–∏–ø—Ç –Ω–∞—Ö–æ–¥–∏—Ç —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ñ–æ—Ç–æ –∏–∑ unified_products/general/
–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤.
"""

import json
import shutil
from pathlib import Path
from typing import Dict, List, Set
import re
from collections import defaultdict

# –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
PROJECT_ROOT = Path(__file__).parent.parent

# –ü—É—Ç—å –∫ unified_products
UNIFIED_PRODUCTS = PROJECT_ROOT / "content" / "unified_products"

# –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –Ω–∞ –ø–∞–ø–∫–∏
PRODUCT_MAPPING = {
    "herbal hand foam": "beloved",
    "floral hand foam": "beloved",
    "dish wash": "beloved",
    "laundry": "beloved",
    "be loved": "beloved",
    "energy diet": "energy_diet",
    "ed smart": "ed_smart",
    "collagen": "collagen",
    "greenflash": "greenflash",
    "green flash": "greenflash",
    "draineffect": "draineffect",
    "drain effect": "draineffect",
    "3d slim": "3d_slim",
    "occuba": "occuba",
    "prohelper": "prohelper",
    "pro helper": "prohelper",
    "omega": "omega",
    "calcium": "calcium",
    "nlka": "nlka",
    "nl–∫–∞": "nlka",
    "sport": "sport",
    "happy smile": "happy_smile",
    "antiage": "antiage",
    "anti age": "antiage",
    "biodrone": "biodrone",
    "biotuning": "biotuning",
    "enerwood": "enerwood",
    "vitamin d": "vitamin_d",
    "starter": "starter_kit",
    "—Å—Ç–∞—Ä—Ç–µ—Ä": "starter_kit",
}


def normalize_product_name(text: str) -> str | None:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–ø–∫—É."""
    text_lower = text.lower()

    # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    text_clean = re.sub(r'[üå±üåÄüìåüñ•‚ùî‚¨Öüì∑üíäüçÉ‚ú®üíöüåøüî•üí™]', '', text_lower).strip()

    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    for key, folder in PRODUCT_MAPPING.items():
        if key in text_clean:
            return folder

    return None


def parse_telegram_export(export_path: Path) -> Dict[str, str]:
    """
    –ü–∞—Ä—Å–∏—Ç Telegram —ç–∫—Å–ø–æ—Ä—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥: {photo_filename: product_folder}.

    –õ–æ–≥–∏–∫–∞:
    1. –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ç–µ–∫—Å—Ç–æ–º (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞)
    2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –Ω–∞–ª–∏—á–∏–µ "üì∑–§–æ—Ç–æ –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π"
    3. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    result_json = export_path / "result.json"

    if not result_json.exists():
        print(f"‚ùå –§–∞–π–ª {result_json} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return {}

    with open(result_json, "r", encoding="utf-8") as f:
        data = json.load(f)

    messages = data.get("messages", [])
    photo_mapping = {}

    current_product = None
    collecting_photos = False

    for i, msg in enumerate(messages):
        msg_type = msg.get("type", "")
        text = msg.get("text", "")

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç - —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
        if isinstance(text, str):
            text_str = text
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
        elif isinstance(text, list):
            text_str = " ".join([item if isinstance(item, str) else item.get("text", "")
                                for item in text])
        else:
            text_str = ""

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–æ–≤–æ–µ –ª–∏ —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞
        if text_str and not text_str.startswith(("‚¨Ö", "üñ•", "üìå", "üåÄ", "‚ùî")):
            product_folder = normalize_product_name(text_str)
            if product_folder:
                current_product = product_folder
                collecting_photos = False
                print(f"üì¶ –ù–∞–π–¥–µ–Ω –ø—Ä–æ–¥—É–∫—Ç: {text_str[:50]} -> {product_folder}")

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–Ω–æ–ø–∫—É "–§–æ—Ç–æ –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π"
        if "üì∑" in text_str and ("—Ñ–æ—Ç–æ" in text_str.lower() or "—Å–æ—Ü—Å–µ—Ç" in text_str.lower()):
            if current_product:
                collecting_photos = True
                print(f"   üì∑ –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä —Ñ–æ—Ç–æ –¥–ª—è {current_product}")

        # 3. –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ç–æ
        if collecting_photos and msg_type == "message":
            photo = msg.get("photo")
            if photo:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                if isinstance(photo, str):
                    photo_file = Path(photo).name
                    photo_mapping[photo_file] = current_product
                    print(f"      ‚úÖ {photo_file} -> {current_product}")

        # 4. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–±–æ—Ä –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ (–∫—Ä–æ–º–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö)
        if collecting_photos and text_str and len(text_str) > 10:
            if not ("—Ñ–æ—Ç–æ" in text_str.lower() or text_str.startswith("NL Assistant")):
                collecting_photos = False
                print(f"   ‚èπ –ó–∞–≤–µ—Ä—à–µ–Ω —Å–±–æ—Ä –¥–ª—è {current_product}")

    return photo_mapping


def move_photos(photo_mapping: Dict[str, str], dry_run: bool = True):
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ñ–æ—Ç–æ –∏–∑ general/ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤.

    Args:
        photo_mapping: –°–ª–æ–≤–∞—Ä—å {photo_filename: product_folder}
        dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ
    """
    general_dir = UNIFIED_PRODUCTS / "general" / "photos"

    if not general_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {general_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    stats = defaultdict(int)
    moved_count = 0
    not_found_count = 0

    for photo_file, product_folder in photo_mapping.items():
        source = general_dir / photo_file

        if not source.exists():
            not_found_count += 1
            continue

        # –¶–µ–ª–µ–≤–∞—è –ø–∞–ø–∫–∞
        target_dir = UNIFIED_PRODUCTS / product_folder / "photos"
        target_dir.mkdir(parents=True, exist_ok=True)

        target = target_dir / photo_file

        if dry_run:
            print(f"[DRY RUN] {photo_file} -> {product_folder}/")
        else:
            shutil.move(str(source), str(target))
            print(f"‚úÖ {photo_file} -> {product_folder}/")

        stats[product_folder] += 1
        moved_count += 1

    print("\n" + "="*60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*60)
    print(f"–í—Å–µ–≥–æ –º–∞–ø–ø–∏–Ω–≥–æ–≤: {len(photo_mapping)}")
    print(f"–ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {moved_count}")
    print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ: {not_found_count}")
    print()
    print("–ü–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º:")
    for product, count in sorted(stats.items(), key=lambda x: -x[1]):
        print(f"  {product}: {count} —Ñ–æ—Ç–æ")


def main():
    import sys

    if len(sys.argv) < 2:
        print("Usage: python map_photos_to_products.py <path_to_telegram_export> [--execute]")
        print()
        print("–ê—Ä–≥—É–º–µ–Ω—Ç—ã:")
        print("  <path_to_telegram_export>  –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å result.json")
        print("  --execute                  –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ (–±–µ–∑ —Ñ–ª–∞–≥–∞ - dry run)")
        print()
        print("–ü—Ä–∏–º–µ—Ä:")
        print('  python map_photos_to_products.py "C:/Users/mafio/Downloads/NL Assistant AI"')
        print('  python map_photos_to_products.py "C:/Users/mafio/Downloads/NL Assistant AI" --execute')
        return

    export_path = Path(sys.argv[1])
    dry_run = "--execute" not in sys.argv

    if not export_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {export_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    print("="*60)
    print("–ü–ê–†–°–ò–ù–ì TELEGRAM –≠–ö–°–ü–û–†–¢–ê")
    print("="*60)
    print(f"–≠–∫—Å–ø–æ—Ä—Ç: {export_path}")
    print(f"–†–µ–∂–∏–º: {'DRY RUN (—Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑)' if dry_run else '–í–´–ü–û–õ–ù–ï–ù–ò–ï'}")
    print()

    # –ü–∞—Ä—Å–∏–º —ç–∫—Å–ø–æ—Ä—Ç
    photo_mapping = parse_telegram_export(export_path)

    if not photo_mapping:
        print("\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞ —Ñ–æ—Ç–æ -> –ø—Ä–æ–¥—É–∫—Ç")
        return

    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(photo_mapping)} –º–∞–ø–ø–∏–Ω–≥–æ–≤")
    print()

    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–æ—Ç–æ
    if dry_run:
        print("‚ö†Ô∏è  DRY RUN MODE - —Ñ–∞–π–ª—ã –ù–ï –±—É–¥—É—Ç –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã")
        print("    –î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ–±–∞–≤—å—Ç–µ —Ñ–ª–∞–≥ --execute")
        print()

    move_photos(photo_mapping, dry_run=dry_run)

    if dry_run:
        print("\n‚ö†Ô∏è  –≠—Ç–æ –±—ã–ª DRY RUN. –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å --execute")


if __name__ == "__main__":
    main()
