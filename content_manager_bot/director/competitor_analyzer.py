"""
CompetitorAnalyzer â€” Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Telethon.

Ð’Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: MarketMuse (competitive analysis), Lately.ai (voice extraction).

Ð Ð°Ð· Ð² Ð½ÐµÐ´ÐµÐ»ÑŽ Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ 30 Ð¿Ð¾ÑÑ‚Ð¾Ð² Ð¸Ð· ÐºÐ°Ð½Ð°Ð»Ð¾Ð² ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²,
Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ Ñ‚Ð¾Ð¿-10 Ð¿Ð¾ engagement, Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· Deepseek.
"""
import json
from datetime import datetime, timedelta
from typing import Optional

from loguru import logger

from shared.ai_clients.deepseek_client import DeepseekClient
from content_manager_bot.director.channel_memory import get_channel_memory


class CompetitorAnalyzer:
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð½Ñ‹Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð² Ð¿Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ð¼."""

    # ÐšÐ°Ð½Ð°Ð»Ñ‹ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ð¿Ð¾ Ð½Ð¸ÑˆÐ°Ð¼
    # Ð›ÐµÐ³ÐºÐ¾ Ñ€Ð°ÑÑˆÐ¸Ñ€ÑÐµÑ‚ÑÑ: "mama": [...], "student": [...]
    COMPETITOR_CHANNELS = {
        "zozh": ["@zdorovie_ru", "@pp_recepty", "@zozh_blog"],
        "business": ["@business_ru", "@dengi_tips", "@mlm_success"],
    }

    def __init__(self):
        self._ai_client: Optional[DeepseekClient] = None

    def _get_ai(self) -> DeepseekClient:
        if self._ai_client is None:
            self._ai_client = DeepseekClient()
        return self._ai_client

    async def analyze(self, segment: str) -> Optional[dict]:
        """ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°.

        Returns:
            dict: {trending_topics, winning_formats, hooks_that_work, our_angle}
        """
        try:
            # 1. Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿Ð¾ÑÑ‚Ñ‹ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²
            all_posts = await self._fetch_competitor_posts(segment)

            if not all_posts:
                logger.info(f"[DIRECTOR] No competitor posts for {segment}, skipping analysis")
                return None

            # 2. ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ñ‚Ð¾Ð¿-10 Ð¿Ð¾ reactions/views
            sorted_posts = sorted(
                all_posts,
                key=lambda p: p.get("reactions", 0) + p.get("views", 0) * 0.01,
                reverse=True,
            )
            top_posts = sorted_posts[:10]

            # 3. AI Ð°Ð½Ð°Ð»Ð¸Ð·
            posts_block = "\n\n".join([
                f"{i+1}. [{p.get('reactions', 0)} Ñ€ÐµÐ°ÐºÑ†Ð¸Ð¹, {p.get('views', 0)} Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð²] "
                f"{p.get('channel', '?')}: \"{p.get('text', '')[:200]}\""
                for i, p in enumerate(top_posts)
            ])

            prompt = f"""Ð’Ð¾Ñ‚ 10 ÑÐ°Ð¼Ñ‹Ñ… ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ð¿Ð¾ÑÑ‚Ð¾Ð² ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð½Ð¸ÑˆÐµ {segment} Ð·Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ:

{posts_block}

ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¡Ð¢Ð ÐžÐ“Ðž JSON (Ð±ÐµÐ· markdown):
{{
  "trending_topics": ["Ñ‚ÐµÐ¼Ð°1", "Ñ‚ÐµÐ¼Ð°2", "Ñ‚ÐµÐ¼Ð°3"],
  "winning_formats": ["Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚1", "Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚2"],
  "hooks_that_work": ["Ñ…ÑƒÐº1", "Ñ…ÑƒÐº2"],
  "our_angle": "Ð¾Ð´Ð½Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ â€” Ñ‡ÐµÐ¼ Ð¼Ñ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ñ‚ÑŒÑÑ"
}}"""

            ai = self._get_ai()
            response = await ai.generate_response(
                system_prompt="Ð¢Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°. ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑˆÑŒ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð²Ñ‹ÑÐ²Ð»ÑÐµÑˆÑŒ Ñ‚Ñ€ÐµÐ½Ð´Ñ‹. ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÑˆÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON.",
                user_message=prompt,
                temperature=0.7,
                max_tokens=500,
            )

            # ÐŸÐ°Ñ€ÑÐ¸Ð¼
            insights = self._parse_insights(response)
            if not insights:
                logger.error(f"[DIRECTOR] Failed to parse competitor insights for {segment}")
                return None

            # 4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² ChannelMemory
            memory = get_channel_memory()
            await memory.set_competitor_insights(segment, insights)

            logger.info(f"[DIRECTOR] Competitor analysis complete for {segment}: {insights.get('trending_topics', [])}")
            return insights

        except Exception as e:
            logger.error(f"[DIRECTOR] Competitor analysis error: {e}")
            return None

    async def get_competitor_insights(self, segment: str) -> str:
        """Ð¡Ñ‚Ñ€Ð¾ÐºÐ° Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°."""
        memory = get_channel_memory()
        state = await memory.get_state(segment)
        insights = state.get("competitor_insights", {})

        if not insights:
            return ""

        lines = ["ðŸ” ÐšÐžÐÐšÐ£Ð Ð•ÐÐ¢Ð«:"]

        topics = insights.get("trending_topics", [])
        if topics:
            lines.append(f"Trending: {', '.join(topics[:5])}")

        formats = insights.get("winning_formats", [])
        if formats:
            lines.append(f"Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: {', '.join(formats[:3])}")

        angle = insights.get("our_angle", "")
        if angle:
            lines.append(f"ÐÐ°Ñˆ ÑƒÐ³Ð¾Ð»: {angle}")

        return "\n".join(lines)

    async def _fetch_competitor_posts(self, segment: str) -> list[dict]:
        """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ Ð¿Ð¾ÑÑ‚Ñ‹ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Telethon Ð¸Ð»Ð¸ ChannelFetcher."""
        channels = self.COMPETITOR_CHANNELS.get(segment, [])
        if not channels:
            return []

        all_posts = []

        try:
            # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ñ‡ÐµÑ€ÐµÐ· ChannelFetcher (shared)
            from shared.style_monitor.channel_fetcher import ChannelFetcher

            fetcher = ChannelFetcher()
            await fetcher.connect()

            for channel in channels:
                try:
                    posts = await fetcher.fetch_posts(
                        channel_id=channel,
                        limit=30,
                        min_date=datetime.utcnow() - timedelta(days=7),
                    )

                    for p in posts:
                        if p.get("text"):
                            all_posts.append({
                                "channel": channel,
                                "text": p["text"],
                                "views": p.get("views", 0),
                                "reactions": p.get("reactions", 0),
                                "date": p.get("date"),
                            })

                except Exception as e:
                    logger.warning(f"[DIRECTOR] Failed to fetch {channel}: {e}")
                    continue

            logger.info(f"[DIRECTOR] Fetched {len(all_posts)} competitor posts for {segment}")

        except ImportError:
            logger.warning("[DIRECTOR] ChannelFetcher not available, skipping competitor fetch")
        except Exception as e:
            logger.warning(f"[DIRECTOR] Competitor fetch error: {e}")

        return all_posts

    def _parse_insights(self, response: str) -> Optional[dict]:
        """ÐŸÐ°Ñ€ÑÐ¸Ñ‚ insights Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° AI."""
        try:
            text = response.strip()
            if text.startswith("```"):
                lines = text.split("\n")
                text = "\n".join(lines[1:-1] if lines[-1].strip() == "```" else lines[1:])

            start = text.find('{')
            end = text.rfind('}')
            if start == -1 or end == -1:
                return None

            data = json.loads(text[start:end + 1])

            # ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
            if "trending_topics" in data:
                return data

            return None

        except (json.JSONDecodeError, ValueError):
            return None


# Singleton
_analyzer: Optional[CompetitorAnalyzer] = None


def get_competitor_analyzer() -> CompetitorAnalyzer:
    global _analyzer
    if _analyzer is None:
        _analyzer = CompetitorAnalyzer()
    return _analyzer
