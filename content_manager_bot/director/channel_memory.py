"""
ChannelMemory ‚Äî Structured Memory (Mem0/A.U.D.N. —Å—Ç–∏–ª—å).

–í–º–µ—Å—Ç–æ —Ç—É–ø–æ–≥–æ ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–µ 15 –ø–æ—Å—Ç–æ–≤¬ª ‚Üí –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–∞–Ω–∞–ª–∞:
- Topic Authority Map (MarketMuse)
- Narrative threads
- Performance memory (top/worst)
- Voice fingerprint (Lately.ai)
- Reflection rules (–∏–∑ ReflectionEngine)

A.U.D.N. —Ü–∏–∫–ª: Add / Update / Delete / No-op.
"""
import re
from datetime import datetime, timedelta
from typing import Optional

from loguru import logger
from sqlalchemy import select

from shared.database.base import AsyncSessionLocal
from content_manager_bot.database.director_models import ChannelMemoryModel
from content_manager_bot.database.models import Post


class ChannelMemory:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–º—è—Ç—å –∫–∞–Ω–∞–ª–∞."""

    # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    DEFAULT_STATE = {
        "total_posts": 0,
        "topic_coverage": {},
        "topic_gaps": [],
        "active_threads": [],
        "pending_questions": [],
        "top_posts": [],
        "worst_posts": [],
        "avg_length": 0,
        "emoji_density": 0.0,
        "question_rate": 0.0,
        "cta_rate": 0.0,
        "reflection_rules": [],
        "rejection_log": [],
        "competitor_insights": {},
        "keyword_baseline": {},
        "last_updated": None,
    }

    async def get_state(self, segment: str) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–∞–Ω–∞–ª–∞."""
        try:
            async with AsyncSessionLocal() as session:
                result = await session.execute(
                    select(ChannelMemoryModel).where(ChannelMemoryModel.segment == segment)
                )
                record = result.scalar_one_or_none()

                if record and record.state_data:
                    # Merge defaults with stored data
                    state = {**self.DEFAULT_STATE, **record.state_data}
                    return state

                return dict(self.DEFAULT_STATE)

        except Exception as e:
            logger.warning(f"[DIRECTOR] get_state error: {e}")
            return dict(self.DEFAULT_STATE)

    async def update_after_publish(self, segment: str, post_content: str, post_type: str,
                                    post_id: int, engagement_rate: Optional[float] = None):
        """A.U.D.N. —Ü–∏–∫–ª –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞."""
        try:
            state = await self.get_state(segment)

            # === ADD ===
            state["total_posts"] += 1

            # Topic coverage: –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            topics = self._extract_topics(post_content)
            for topic in topics:
                state["topic_coverage"][topic] = state["topic_coverage"].get(topic, 0) + 1

            # === UPDATE ===
            # Active threads: –µ—Å–ª–∏ —Ç–µ–º–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π
            for thread in state.get("active_threads", []):
                thread_topic = thread.get("topic", "").lower()
                if any(t.lower() in thread_topic or thread_topic in t.lower() for t in topics):
                    thread["posts_count"] = thread.get("posts_count", 0) + 1
                    thread["last_mention"] = datetime.utcnow().isoformat()

            # Pending questions: –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≤–æ–ø—Ä–æ—Å –≤ –∫–æ–Ω—Ü–µ
            last_100 = post_content[-100:] if len(post_content) > 100 else post_content
            if '?' in last_100:
                question = last_100.split('?')[0].split('\n')[-1].strip() + '?'
                if len(question) > 10:
                    questions = state.get("pending_questions", [])
                    questions.append(question[:100])
                    state["pending_questions"] = questions[-5:]  # keep last 5

            # Performance memory
            if engagement_rate is not None:
                post_info = {
                    "id": post_id,
                    "preview": post_content[:80],
                    "type": post_type,
                    "engagement": engagement_rate,
                }

                # Top posts
                top = state.get("top_posts", [])
                top.append(post_info)
                top.sort(key=lambda x: x.get("engagement", 0), reverse=True)
                state["top_posts"] = top[:5]

                # Worst posts
                worst = state.get("worst_posts", [])
                worst.append(post_info)
                worst.sort(key=lambda x: x.get("engagement", 0))
                state["worst_posts"] = worst[:3]

            # === DELETE ===
            # –£–¥–∞–ª—è–µ–º threads —Å—Ç–∞—Ä—à–µ 14 –¥–Ω–µ–π
            now = datetime.utcnow()
            active_threads = []
            for thread in state.get("active_threads", []):
                last_mention = thread.get("last_mention")
                if last_mention:
                    try:
                        last_dt = datetime.fromisoformat(last_mention)
                        if (now - last_dt).days < 14:
                            active_threads.append(thread)
                    except (ValueError, TypeError):
                        active_threads.append(thread)
                else:
                    active_threads.append(thread)
            state["active_threads"] = active_threads

            # === NO-OP: Voice fingerprint –∫–∞–∂–¥—ã–µ 5 –ø–æ—Å—Ç–æ–≤ ===
            if state["total_posts"] % 5 == 0:
                await self._update_voice_fingerprint(state, segment)

            # Topic gaps
            all_expected_topics = self._get_expected_topics(segment)
            state["topic_gaps"] = [
                t for t in all_expected_topics
                if state["topic_coverage"].get(t, 0) < 2
            ]

            state["last_updated"] = now.isoformat()

            # Save
            await self._save_state(segment, state)
            logger.info(f"[DIRECTOR] ChannelMemory updated for {segment}: {state['total_posts']} posts")

        except Exception as e:
            logger.error(f"[DIRECTOR] update_after_publish error: {e}")

    async def get_context_for_prompt(self, segment: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É (~200 —Ç–æ–∫–µ–Ω–æ–≤) –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞."""
        state = await self.get_state(segment)

        if state["total_posts"] == 0:
            return ""

        lines = [f"üìä –ö–ê–ù–ê–õ ({segment}, {state['total_posts']} –ø–æ—Å—Ç–æ–≤):"]

        # –°–∏–ª—å–Ω—ã–µ —Ç–µ–º—ã
        coverage = state.get("topic_coverage", {})
        if coverage:
            sorted_topics = sorted(coverage.items(), key=lambda x: x[1], reverse=True)[:5]
            topics_str = ", ".join(f"{t} ({c})" for t, c in sorted_topics)
            lines.append(f"–°–∏–ª—å–Ω—ã–µ —Ç–µ–º—ã: {topics_str}")

        # –ü—Ä–æ–±–µ–ª—ã
        gaps = state.get("topic_gaps", [])
        if gaps:
            lines.append(f"–ü—Ä–æ–±–µ–ª—ã: {', '.join(gaps[:5])}")

        # –ù–∏—Ç–∏
        threads = state.get("active_threads", [])
        if threads:
            threads_str = ", ".join(f'"{t["topic"]}" ({t.get("posts_count", 1)} –ø.)' for t in threads[:3])
            lines.append(f"–ê–∫—Ç–∏–≤–Ω—ã–µ –Ω–∏—Ç–∏: {threads_str}")

        # –ù–µ—Ä–∞—Å–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        questions = state.get("pending_questions", [])
        if questions:
            lines.append(f"–ù–µ—Ä–∞—Å–∫—Ä—ã—Ç—ã–π –≤–æ–ø—Ä–æ—Å: \"{questions[-1]}\"")

        # –¢–æ–ø-–ø–æ—Å—Ç
        top = state.get("top_posts", [])
        if top:
            best = top[0]
            lines.append(f"–¢–æ–ø-–ø–æ—Å—Ç: {best['type']} ({best.get('engagement', 0):.1f}% eng)")

        # Voice
        if state.get("avg_length"):
            q_rate = state.get("question_rate", 0)
            lines.append(f"Voice: —Å—Ä–µ–¥–Ω—è—è {state['avg_length']} —Å–∏–º–≤–æ–ª–æ–≤, –≤–æ–ø—Ä–æ—Å –≤ {q_rate:.0%} –ø–æ—Å—Ç–æ–≤")

        # Reflection rules
        rules = state.get("reflection_rules", [])
        if rules:
            lines.append(f"–£—Ä–æ–∫–∏ –∏–∑ –ø—Ä–∞–≤–æ–∫: {'; '.join(rules[:3])}")

        # Competitor insights
        insights = state.get("competitor_insights", {})
        if insights.get("trending_topics"):
            lines.append(f"Trending —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {', '.join(insights['trending_topics'][:3])}")

        return "\n".join(lines)

    async def add_thread(self, segment: str, topic: str, post_id: int):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –Ω–∞—Ä—Ä–∞—Ç–∏–≤–Ω—É—é –Ω–∏—Ç—å."""
        state = await self.get_state(segment)
        threads = state.get("active_threads", [])
        threads.append({
            "topic": topic,
            "started_post_id": post_id,
            "posts_count": 1,
            "last_mention": datetime.utcnow().isoformat(),
        })
        state["active_threads"] = threads[-10:]  # max 10
        await self._save_state(segment, state)

    async def add_rejection(self, segment: str, original_content: str, action: str,
                            reason: str, post_type: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ/–ø—Ä–∞–≤–∫—É –¥–ª—è ReflectionEngine."""
        state = await self.get_state(segment)

        log = state.get("rejection_log", [])
        log.append({
            "original_preview": original_content[:200],
            "action": action,  # "reject" or "edit"
            "reason": reason,
            "post_type": post_type,
            "timestamp": datetime.utcnow().isoformat(),
        })
        state["rejection_log"] = log[-10:]  # keep last 10

        await self._save_state(segment, state)
        logger.info(f"[DIRECTOR] Rejection logged for {segment}: {action}")

    async def set_reflection_rules(self, segment: str, rules: list[str]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ ReflectionEngine."""
        state = await self.get_state(segment)
        state["reflection_rules"] = rules[-10:]  # max 10
        await self._save_state(segment, state)
        logger.info(f"[DIRECTOR] Reflection rules updated for {segment}: {len(rules)} rules")

    async def set_competitor_insights(self, segment: str, insights: dict):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç insights –æ—Ç CompetitorAnalyzer."""
        state = await self.get_state(segment)
        state["competitor_insights"] = insights
        await self._save_state(segment, state)
        logger.info(f"[DIRECTOR] Competitor insights updated for {segment}")

    async def update_keyword_baseline(self, segment: str, baseline: dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–æ–Ω–æ–≤—É—é —á–∞—Å—Ç–æ—Ç—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è TrendDetector."""
        state = await self.get_state(segment)
        state["keyword_baseline"] = baseline
        await self._save_state(segment, state)

    async def _update_voice_fingerprint(self, state: dict, segment: str):
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç voice fingerprint (–∫–∞–∂–¥—ã–µ 5 –ø–æ—Å—Ç–æ–≤)."""
        try:
            async with AsyncSessionLocal() as session:
                result = await session.execute(
                    select(Post.content).where(
                        Post.status == "published",
                        Post.segment == segment,
                    ).order_by(Post.published_at.desc()).limit(20)
                )
                contents = [row[0] for row in result.all()]

                if not contents:
                    return

                # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞
                state["avg_length"] = int(sum(len(c) for c in contents) / len(contents))

                # Emoji density
                total_emojis = sum(len(re.findall(r'[\U0001f600-\U0001f999]', c)) for c in contents)
                total_chars = sum(len(c) for c in contents)
                state["emoji_density"] = total_emojis / max(total_chars, 1)

                # Question rate
                questions = sum(1 for c in contents if '?' in c[-100:])
                state["question_rate"] = questions / len(contents)

                # CTA rate
                cta_markers = ["–ø–∏—à–∏", "–ø–µ—Ä–µ—Ö–æ–¥–∏", "—Å—Å—ã–ª–∫", "–±–æ—Ç", "@"]
                ctas = sum(1 for c in contents if any(m in c.lower() for m in cta_markers))
                state["cta_rate"] = ctas / len(contents)

                logger.info(
                    f"[DIRECTOR] Voice fingerprint updated: avg_len={state['avg_length']}, "
                    f"question_rate={state['question_rate']:.0%}"
                )

        except Exception as e:
            logger.warning(f"[DIRECTOR] Voice fingerprint update failed: {e}")

    def _extract_topics(self, content: str) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏–∑ –ø–æ—Å—Ç–∞ (–ø—Ä–æ—Å—Ç–æ–π TF)."""
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            "—ç—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–¥–ª—è", "—É–∂–µ", "–≤—Å–µ", "–≤–æ—Ç", "—Ç–∞–∫", "—Ç–æ–∂–µ",
            "–µ—Å—Ç—å", "–º–Ω–µ", "–º–æ–π", "–≥–¥–µ", "—Ç—É—Ç", "—Ç–∞–º", "–æ–Ω–∏", "–æ–Ω–∞", "–µ–º—É",
            "–µ—Å–ª–∏", "–∫–æ–≥–¥–∞", "–ø–æ—Ç–æ–º—É", "—á—Ç–æ–±—ã", "–º–æ–∂–µ—Ç", "–Ω–µ—Ç", "–ø—Ä–æ—Å—Ç–æ",
            "–æ—á–µ–Ω—å", "–¥–∞–∂–µ", "–∏–ª–∏", "–ø—Ä–∏", "–±–µ–∑", "–µ—â—ë", "–µ—â–µ", "–±—ã–ª",
            "–±—ã–ª–∞", "–±—ã–ª–æ", "–±—ã–ª–∏", "–±—É–¥–µ—Ç", "–±—É–¥—É", "–∫–æ—Ç–æ—Ä—ã–µ", "–∫–æ—Ç–æ—Ä—ã–π",
            "–∫–æ—Ç–æ—Ä–∞—è", "–∫–æ—Ç–æ—Ä–æ–µ", "–ø–æ—Å–ª–µ", "—á–µ—Ä–µ–∑", "–º–µ–∂–¥—É", "–ø–µ—Ä–µ–¥",
        }

        words = re.findall(r'[–∞-—è—ë–ê-–Ø–Å]{4,}', content.lower())
        words = [w for w in words if w not in stop_words and len(w) > 3]

        # –ë–µ—Ä—ë–º 3 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö
        freq = {}
        for w in words:
            freq[w] = freq.get(w, 0) + 1

        sorted_words = sorted(freq.items(), key=lambda x: x[1], reverse=True)
        return [w for w, _ in sorted_words[:3]]

    def _get_expected_topics(self, segment: str) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—ã–µ —Ç–µ–º—ã –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞."""
        expected = {
            "zozh": ["—Å–ø–æ—Ä—Ç", "–ø–∏—Ç–∞–Ω–∏–µ", "—Ä–µ—Ü–µ–ø—Ç—ã", "–º–æ—Ç–∏–≤–∞—Ü–∏—è", "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ", "—Å–æ–Ω", "–ø—Ä–∏–≤—ã—á–∫–∏"],
            "business": ["–¥–æ—Ö–æ–¥", "–ø—Ä–æ–¥–∞–∂–∏", "–∫–æ–º–∞–Ω–¥–∞", "–º–æ—Ç–∏–≤–∞—Ü–∏—è", "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã", "—Ä–æ—Å—Ç"],
            "mama": ["–¥–µ—Ç–∏", "–∑–¥–æ—Ä–æ–≤—å–µ", "–ø–∏—Ç–∞–Ω–∏–µ", "—ç–Ω–µ—Ä–≥–∏—è", "–≤—Ä–µ–º—è", "–±–∞–ª–∞–Ω—Å"],
            "student": ["—É—á—ë–±–∞", "–¥–µ–Ω—å–≥–∏", "–º–æ—Ç–∏–≤–∞—Ü–∏—è", "–ø–æ–¥—Ä–∞–±–æ—Ç–∫–∞", "–ø—Ä–∏–≤—ã—á–∫–∏"],
        }
        return expected.get(segment, ["–º–æ—Ç–∏–≤–∞—Ü–∏—è", "–ø—Ä–æ–¥—É–∫—Ç", "–ø—É—Ç—å", "—á–µ—Å—Ç–Ω–æ—Å—Ç—å"])

    async def _save_state(self, segment: str, state: dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ –ë–î."""
        try:
            async with AsyncSessionLocal() as session:
                result = await session.execute(
                    select(ChannelMemoryModel).where(ChannelMemoryModel.segment == segment)
                )
                record = result.scalar_one_or_none()

                if record:
                    record.state_data = state
                    record.updated_at = datetime.utcnow()
                else:
                    record = ChannelMemoryModel(
                        segment=segment,
                        state_data=state,
                        updated_at=datetime.utcnow(),
                    )
                    session.add(record)

                await session.commit()

        except Exception as e:
            logger.error(f"[DIRECTOR] _save_state error: {e}")


# Singleton
_memory: Optional[ChannelMemory] = None


def get_channel_memory() -> ChannelMemory:
    global _memory
    if _memory is None:
        _memory = ChannelMemory()
    return _memory
